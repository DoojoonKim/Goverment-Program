[[데이터 수집(웹스크래핑) 및 분석]]

1. 데이터 수집 
- urllib + beautiful soup(모든 페이지 정보가 다 응답이 오면 OK)

- request + beautiful soup(모든 페이지 정보가 다 응답이 오면 OK)
- open api(ex kakaoAPI)

- selenium(=마케팅, 드루킹)

2. 웹을 직접 연결하여 수집하는 방식
- 공공데이터가 없음
- 원하는 유형으로 데이터가 존재하지 않는다.
- SPA(Single Page Application) 형태의 경우(앵귤러, 리액트, 뷰에로 만들어진 사이트)
- 자동화처리 => 윈도우(스케쥴러) or 리눅스(cron)=>디도스로 간주 => proxy 서버를 통한 우회 및 유저에이전트 조작 필요, 
                        소프트웨어 스타일 제공(GUI(qt5(비쌈),tinker(스펠링 틀릴 수 있음..) + 패키징 배포(상품화)+ 서버(http 기반 웹)) 
3. 데이터 수집 공정
 3-1. 공공데이터나 기업데이터로 제공 받을 수 있는가?
 3-2. elif 오픈 api를 수집할 수 있는가?(포털, 서비스 제공자 등)
 3-3. elif  urllib를 통해서 웹페이지를 긁으면(스크래핑)하면 수집 할 수 있는가?
 3-4. else selenium으로 긁으면(크롤링) 수집할 수 있는가?
     PC기반 웹 접근이 불편하면 모바일로 접근